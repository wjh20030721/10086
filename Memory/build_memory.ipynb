{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zhc23013\\AppData\\Local\\miniconda3\\envs\\rag-ad\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "init\n",
    "\"\"\"\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "import ast\n",
    "import pdb\n",
    "import clip\n",
    "import json\n",
    "import torch\n",
    "import faiss\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "# init clip\n",
    "clip_model, preprocess = clip.load(\"ViT-B/16\", device=\"cuda\")\n",
    "\n",
    "# save index\n",
    "def index_save(index_split, path):\n",
    "    faiss.write_index(index_split, path)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process::   0%|          | 0/12288 [00:00<?, ?it/s]c:\\Users\\zhc23013\\AppData\\Local\\miniconda3\\envs\\rag-ad\\Lib\\site-packages\\torch\\nn\\functional.py:5560: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n",
      "Process:: 100%|██████████| 12288/12288 [03:54<00:00, 52.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of indexes: 12288\n",
      "Saving index:\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "build memory\n",
    "\"\"\"\n",
    "file_path = \"C:/Users/zhc23013/Desktop/MLLM_RAG_COT/Memory/reference_image_locations.txt\"\n",
    "with open(file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "image_paths = [line.split()[0] for line in lines]\n",
    "print(len(image_paths))\n",
    "\n",
    "index_img_save_path =  \"C:/Users/zhc23013/Desktop/MLLM_RAG_COT/Memory/memory.index\"\n",
    "\n",
    "index_img = faiss.IndexHNSWFlat(512, 64, faiss.METRIC_INNER_PRODUCT)\n",
    "\n",
    "embed_img = []\n",
    "with torch.no_grad():\n",
    "    for image_path in tqdm(image_paths,desc=\"Process:\"):\n",
    "        image = preprocess(Image.open(image_path)).unsqueeze(0).to(\"cuda\")\n",
    "        image_features = clip_model.encode_image(image)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        embed_img.append(image_features.cpu())\n",
    "embed_img = [np.array(embed) for embed in embed_img]\n",
    "embed_img = np.array(embed_img).squeeze()\n",
    "index_img.add(embed_img)\n",
    "print(\"Total number of indexes:\", index_img.ntotal)\n",
    "\n",
    "print(\"Saving index:\")\n",
    "index_save(index_img, index_img_save_path)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## retrieve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_img_save_path = \"C:/Users/zhc23013/Desktop/MLLM_RAG_COT/Memory/memory.index\"\n",
    "index_img = faiss.read_index(index_img_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "test_image_path = \"C:/Users/zhc23013/Desktop/MLLM_RAG_COT/dataset/MMAD/DS-MVTec/capsule/image/crack/000.png\"\n",
    "\n",
    "def get_image_feature(image_path, clip_model, preprocess):\n",
    "    image = preprocess(Image.open(image_path)).unsqueeze(0).to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        image_features = clip_model.encode_image(image)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    return image_features.cpu().numpy().squeeze()\n",
    "    \n",
    "test_image_feature = get_image_feature(test_image_path, clip_model, preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance: [[0.9959123]]\n",
      "Index of the most similar image: 591\n",
      "Most similar image path: C:\\Users\\zhc23013\\Desktop\\MLLM_RAG_COT\\dataset\\MMAD\\MVTec-AD\\capsule\\train\\good\\158.png\n"
     ]
    }
   ],
   "source": [
    "k = 1  \n",
    "D, I = index_img.search(np.expand_dims(test_image_feature, axis=0), k)\n",
    "\n",
    "print(f\"Distance: {D}\")\n",
    "print(f\"Index of the most similar image: {I[0][0]}\")\n",
    "\n",
    "most_similar_image_path = image_paths[I[0][0]]\n",
    "print(f\"Most similar image path: {most_similar_image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-ad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
